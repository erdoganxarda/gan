{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6141dc9e",
   "metadata": {},
   "source": [
    "# Handwritten Text Generation\n",
    "## Sequence Modeling & GAN-Based Handwriting Style Synthesis\n",
    "\n",
    "---\n",
    "\n",
    "### Problem Description\n",
    "Handwritten text generation is the task of **automatically producing realistic handwriting** — either as images or pen-stroke sequences — that is indistinguishable from human writing.\n",
    "\n",
    "Two core sub-problems:\n",
    "- **Sequence modeling**: Model the temporal dynamics of pen strokes (x, y coordinates over time)\n",
    "- **Image synthesis**: Generate pixel-level handwriting images with realistic style\n",
    "\n",
    "### Why is it hard?\n",
    "- Handwriting is highly **personal and variable** (style, slant, pressure)\n",
    "- Requires modeling **long-range temporal dependencies** in stroke sequences\n",
    "- Must balance **legibility** (correct letter shapes) with **naturalness** (human-like variation)\n",
    "\n",
    "---\n",
    "\n",
    "### Application Examples\n",
    "| Application | Description |\n",
    "|---|---|\n",
    "| Digital assistants | Personalised handwriting fonts from a few samples |\n",
    "| Forgery detection | Generating adversarial samples to train detectors |\n",
    "| Data augmentation | Generating training data for HTR (Handwritten Text Recognition) systems |\n",
    "| Accessibility tools | Restoring handwriting for people with motor disabilities |\n",
    "| Historical document synthesis | Reproducing historical scripts for archival research |\n",
    "\n",
    "---\n",
    "\n",
    "### State-of-the-Art Methods\n",
    "\n",
    "| Method | Year | Key Idea |\n",
    "|---|---|---|\n",
    "| **Graves (2013) RNN** | 2013 | LSTM with Mixture Density Networks for stroke prediction |\n",
    "| **GANwriting** | 2020 | GAN conditioned on writer style + text content |\n",
    "| **ScrabbleGAN** | 2020 | Semi-supervised GAN for arbitrary-length word images |\n",
    "| **HiGAN** | 2021 | Hierarchical GAN with style disentanglement |\n",
    "| **DiffusionHandwriting** | 2023 | Diffusion model for stroke-level generation |\n",
    "\n",
    "---\n",
    "\n",
    "### Analysis of Challenges\n",
    "1. **Mode collapse in GANs** — generator produces limited variety\n",
    "2. **Training instability** — discriminator overpowers generator early\n",
    "3. **Style conditioning** — encoding writer identity without overfitting\n",
    "4. **Evaluation metrics** — FID, WER on generated text are imperfect proxies\n",
    "5. **Long sequence generation** — error accumulation in autoregressive LSTM models\n",
    "6. **Dataset scarcity** — limited labelled handwriting datasets (IAM, RIMES, CVL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8248582",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "**Run the cell below once** to install all required packages into the currently selected Python kernel.\n",
    "\n",
    "> **Recommended**: Create a dedicated environment first (run once in terminal):\n",
    "> ```bash\n",
    "> conda create -n handwriting-gen python=3.10 -y\n",
    "> conda activate handwriting-gen\n",
    "> pip install torch==2.2.2 torchvision==0.17.2 --index-url https://download.pytorch.org/whl/cpu\n",
    "> pip install numpy==1.26.4 matplotlib==3.8.4 pillow==10.2.0 ipykernel==6.29.3\n",
    "> python -m ipykernel install --user --name handwriting-gen --display-name \"Python (handwriting-gen)\"\n",
    "> ```\n",
    "> Then select **\"Python (handwriting-gen)\"** as the kernel in Jupyter before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e00e56b",
   "metadata": {},
   "outputs": [],
   "source": "# Cell-1 : Install all required packages\n# Run this cell once with your selected Python kernel.\n# All packages will be installed into the active environment.\n\nimport sys, subprocess\n\npackages = [\n    \"torch==2.2.2 --index-url https://download.pytorch.org/whl/cpu\",\n    \"torchvision==0.17.2 --index-url https://download.pytorch.org/whl/cpu\",\n    \"numpy==1.26.4\",\n    \"matplotlib==3.8.4\",\n    \"pillow==10.2.0\",\n]\n\nfor pkg in packages:\n    print(f\"Installing: {pkg.split()[0]} ...\")\n    result = subprocess.run(\n        [sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\"] + pkg.split(),\n        capture_output=True, text=True\n    )\n    status = \"OK\" if result.returncode == 0 else f\"FAILED\\n{result.stderr}\"\n    print(f\"  -> {status}\")\n\nprint(\"\\nAll packages installed. Restart kernel if this is the first install.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ff5b31",
   "metadata": {},
   "outputs": [],
   "source": "# Cell-2 : Import libraries and set reproducibility seeds\n\nimport os\nimport json\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport pandas as pd\nfrom pathlib import Path\nfrom PIL import Image\nfrom collections import Counter\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nimport torchvision.datasets as tv_datasets\n\n%matplotlib inline\n\ntorch.manual_seed(42)\nnp.random.seed(42)\nrandom.seed(42)\n\nprint(\"Python :\", __import__('sys').version.split()[0])\nprint(\"PyTorch:\", torch.__version__)\nprint(\"Imports OK\")"
  },
  {
   "cell_type": "markdown",
   "id": "dataset-section",
   "metadata": {},
   "source": [
    "## Dataset: MNIST Handwritten Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca36f5d",
   "metadata": {},
   "outputs": [],
   "source": "# Cell-3 : Download MNIST dataset\n# Dataset is saved inside data/ automatically.\n# No manual download needed — torchvision handles everything.\n\nDATA_DIR = os.path.join(os.getcwd(), \"data\")\nos.makedirs(DATA_DIR, exist_ok=True)\n\nmnist_train = tv_datasets.MNIST(root=DATA_DIR, train=True,  download=True)\nmnist_test  = tv_datasets.MNIST(root=DATA_DIR, train=False, download=True)\n\nprint(f\"Train samples : {len(mnist_train)}\")\nprint(f\"Test  samples : {len(mnist_test)}\")\nprint(f\"Classes       : {mnist_train.classes}\")\nprint(f\"Stored in     : {DATA_DIR}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8cf117",
   "metadata": {},
   "outputs": [],
   "source": "# Cell-4 : Visualise MNIST handwriting samples\n\nfig, axes = plt.subplots(3, 8, figsize=(14, 6))\nfig.suptitle(\"MNIST Dataset Samples (Handwritten Digits 0-9)\", fontsize=14, fontweight=\"bold\")\n\nfor i, ax in enumerate(axes.flat):\n    img, label = mnist_train[i * 200]\n    ax.imshow(img, cmap=\"gray\")\n    ax.set_title(str(label), fontsize=9)\n    ax.axis(\"off\")\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de041e79",
   "metadata": {},
   "outputs": [],
   "source": "# Cell-5 : Create PyTorch Dataset and DataLoader from MNIST\n\ntransform = transforms.Compose([\n    transforms.Resize((32, 32)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\nclass MNISTDataset(Dataset):\n    def __init__(self, base_dataset, transform=None):\n        self.data      = base_dataset\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img, label = self.data[idx]\n        if self.transform:\n            img = self.transform(img)\n        return img, label\n\ntrain_dataset = MNISTDataset(mnist_train, transform=transform)\ntrain_loader  = DataLoader(train_dataset, batch_size=64, shuffle=True)\n\nprint(f\"DataLoader ready — {len(train_dataset)} samples, {len(train_loader)} batches\")"
  },
  {
   "cell_type": "markdown",
   "id": "b8a46a8b",
   "metadata": {},
   "source": [
    "## Part 1 — Sequence Modeling with LSTM\n",
    "### Concept: Pen-Stroke Sequence Prediction\n",
    "\n",
    "Handwriting can be represented as a **sequence of (x, y) pen positions** over time.  \n",
    "An LSTM learns the temporal pattern of strokes and can **predict / generate** the next point given previous points.\n",
    "\n",
    "**Architecture:**\n",
    "```\n",
    "Input (x,y) sequence  →  LSTM (hidden=64)  →  Linear  →  Predicted (x,y)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b029e0d",
   "metadata": {},
   "outputs": [],
   "source": "# Cell-6 : Generate synthetic pen-stroke sequence and visualise\n\ndef generate_stroke(n=150, seed=42):\n    np.random.seed(seed)\n    dx = np.random.randn(n) * 0.5\n    dy = np.random.randn(n) * 0.3\n    x  = np.cumsum(dx)\n    y  = np.cumsum(dy)\n    return np.stack([x, y], axis=1)\n\nstroke = generate_stroke()\n\nplt.figure(figsize=(7, 3))\nplt.plot(stroke[:, 0], stroke[:, 1], color=\"navy\", linewidth=1.5)\nplt.title(\"Synthetic Pen-Stroke Sequence (x, y over time)\", fontweight=\"bold\")\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.tight_layout()\nplt.show()\nprint(f\"Stroke shape: {stroke.shape}  ->  {stroke.shape[0]} time-steps, 2 features (x, y)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a31761",
   "metadata": {},
   "outputs": [],
   "source": "# Cell-7 : Prepare sliding-window sequences for LSTM training\n\nSEQ_LEN = 10\ninputs, targets = [], []\n\nfor i in range(len(stroke) - SEQ_LEN):\n    inputs.append(stroke[i : i + SEQ_LEN])\n    targets.append(stroke[i + 1 : i + SEQ_LEN + 1])\n\ninputs  = torch.tensor(np.array(inputs),  dtype=torch.float32)\ntargets = torch.tensor(np.array(targets), dtype=torch.float32)\n\nprint(f\"inputs  shape: {inputs.shape}   (samples, seq_len, features)\")\nprint(f\"targets shape: {targets.shape}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a08c826",
   "metadata": {},
   "outputs": [],
   "source": "# Cell-8 : Define LSTM model for stroke sequence modeling\n\nclass StrokeLSTM(nn.Module):\n    def __init__(self, input_size=2, hidden_size=64, output_size=2):\n        super().__init__()\n        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n        self.fc   = nn.Linear(hidden_size, output_size)\n\n    def forward(self, x):\n        out, _ = self.lstm(x)\n        return self.fc(out)\n\nlstm_model = StrokeLSTM()\nprint(lstm_model)\ntotal_params = sum(p.numel() for p in lstm_model.parameters())\nprint(f\"\\nTotal trainable parameters: {total_params:,}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50f7470",
   "metadata": {},
   "outputs": [],
   "source": "# Cell-9 : Train LSTM and plot training loss\n\noptimizer = torch.optim.Adam(lstm_model.parameters(), lr=0.01)\nloss_fn   = nn.MSELoss()\nlosses    = []\n\nlstm_model.train()\nfor epoch in range(100):\n    pred  = lstm_model(inputs)\n    loss  = loss_fn(pred, targets)\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    losses.append(loss.item())\n\nplt.figure(figsize=(7, 3))\nplt.plot(losses, color=\"steelblue\")\nplt.title(\"LSTM Training Loss (MSE)\", fontweight=\"bold\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.tight_layout()\nplt.show()\nprint(f\"Final loss: {losses[-1]:.6f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64d53ba",
   "metadata": {},
   "outputs": [],
   "source": "# Cell-10 : Generate strokes with trained LSTM — Real vs Generated\n\nlstm_model.eval()\nwith torch.no_grad():\n    cur = inputs[0:1].clone()\n    generated = []\n    for _ in range(120):\n        pred = lstm_model(cur)\n        nxt  = pred[:, -1:, :]\n        generated.append(nxt.numpy()[0][0])\n        cur  = torch.cat([cur[:, 1:, :], nxt], dim=1)\n\ngenerated = np.array(generated)\n\nfig, axes = plt.subplots(1, 2, figsize=(10, 4))\naxes[0].plot(stroke[:, 0], stroke[:, 1], color=\"navy\", linewidth=1.5)\naxes[0].set_title(\"Real Stroke Sequence\", fontweight=\"bold\")\naxes[0].axis(\"off\")\n\naxes[1].plot(generated[:, 0], generated[:, 1], color=\"crimson\", linewidth=1.5)\naxes[1].set_title(\"LSTM Generated Stroke\", fontweight=\"bold\")\naxes[1].axis(\"off\")\n\nplt.suptitle(\"Sequence Modeling: Real vs LSTM Generated\", fontsize=13)\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "d39009f1",
   "metadata": {},
   "source": [
    "## Part 2 — GAN-Based Handwriting Style Synthesis\n",
    "### Concept: Generative Adversarial Network for Handwriting\n",
    "\n",
    "A GAN consists of two competing networks:\n",
    "- **Generator (G)**: Takes random noise and produces fake handwriting strokes\n",
    "- **Discriminator (D)**: Distinguishes real strokes from fake ones\n",
    "\n",
    "They train together in a **minimax game** until G fools D consistently.\n",
    "\n",
    "```\n",
    "Noise z ~ N(0,1)  ->  Generator  ->  Fake stroke\n",
    "                                          |\n",
    "Real stroke  ->  Discriminator  ->  Real / Fake?\n",
    "```\n",
    "\n",
    "**Key challenge**: Mode collapse — G may produce only a narrow range of outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fda9c10",
   "metadata": {},
   "outputs": [],
   "source": "# Cell-11 : Define GAN Generator and Discriminator\n\nNOISE_DIM  = 20\nSTROKE_DIM = 60  # 30 (x,y) points flattened\n\nclass Generator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(NOISE_DIM, 128),\n            nn.LeakyReLU(0.2),\n            nn.Linear(128, 256),\n            nn.LeakyReLU(0.2),\n            nn.Linear(256, STROKE_DIM),\n            nn.Tanh()\n        )\n    def forward(self, z):\n        return self.net(z)\n\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(STROKE_DIM, 256),\n            nn.LeakyReLU(0.2),\n            nn.Linear(256, 128),\n            nn.LeakyReLU(0.2),\n            nn.Linear(128, 1),\n            nn.Sigmoid()\n        )\n    def forward(self, x):\n        return self.net(x)\n\nG = Generator()\nD = Discriminator()\nprint(\"Generator:    \", sum(p.numel() for p in G.parameters()), \"params\")\nprint(\"Discriminator:\", sum(p.numel() for p in D.parameters()), \"params\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39be4c6e",
   "metadata": {},
   "outputs": [],
   "source": "# Cell-12 : Train GAN and plot Generator / Discriminator losses\n\nopt_G = torch.optim.Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.999))\nopt_D = torch.optim.Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999))\nbce   = nn.BCELoss()\n\ng_losses, d_losses = [], []\nBATCH  = 32\nEPOCHS = 200\n\nfor epoch in range(EPOCHS):\n    idx     = np.random.randint(0, len(stroke) - STROKE_DIM // 2, BATCH)\n    real_np = np.array([stroke[i : i + STROKE_DIM // 2].flatten() for i in idx])\n    real    = torch.tensor(real_np, dtype=torch.float32)\n    real    = (real - real.mean()) / (real.std() + 1e-8)\n\n    noise    = torch.randn(BATCH, NOISE_DIM)\n    fake     = G(noise).detach()\n    real_lbl = torch.ones(BATCH,  1)\n    fake_lbl = torch.zeros(BATCH, 1)\n\n    d_loss = bce(D(real), real_lbl) + bce(D(fake), fake_lbl)\n    opt_D.zero_grad(); d_loss.backward(); opt_D.step()\n\n    noise  = torch.randn(BATCH, NOISE_DIM)\n    g_loss = bce(D(G(noise)), real_lbl)\n    opt_G.zero_grad(); g_loss.backward(); opt_G.step()\n\n    g_losses.append(g_loss.item())\n    d_losses.append(d_loss.item())\n\nplt.figure(figsize=(8, 3))\nplt.plot(g_losses, label=\"Generator\",     color=\"crimson\",   linewidth=1.2)\nplt.plot(d_losses, label=\"Discriminator\", color=\"steelblue\", linewidth=1.2)\nplt.legend()\nplt.title(\"GAN Training Loss\", fontweight=\"bold\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"BCE Loss\")\nplt.tight_layout()\nplt.show()\nprint(f\"Final G loss: {g_losses[-1]:.4f}  |  Final D loss: {d_losses[-1]:.4f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91efc8c",
   "metadata": {},
   "outputs": [],
   "source": "# Cell-13 : Generate handwriting strokes using trained GAN — Real vs GAN\n\nG.eval()\nwith torch.no_grad():\n    fig, axes = plt.subplots(2, 4, figsize=(14, 6))\n    fig.suptitle(\"GAN Generated Strokes vs Real Stroke Segments\", fontsize=13, fontweight=\"bold\")\n\n    for col in range(4):\n        start = col * 30\n        seg   = stroke[start : start + 30]\n        axes[0, col].plot(seg[:, 0], seg[:, 1], color=\"navy\", linewidth=1.5)\n        axes[0, col].set_title(f\"Real #{col+1}\", fontsize=9)\n        axes[0, col].axis(\"off\")\n\n        noise = torch.randn(1, NOISE_DIM)\n        fake  = G(noise).numpy().reshape(-1, 2)\n        axes[1, col].plot(fake[:, 0], fake[:, 1], color=\"crimson\", linewidth=1.5)\n        axes[1, col].set_title(f\"GAN #{col+1}\", fontsize=9)\n        axes[1, col].axis(\"off\")\n\n    axes[0, 0].set_ylabel(\"Real\",      fontsize=10, fontweight=\"bold\")\n    axes[1, 0].set_ylabel(\"Generated\", fontsize=10, fontweight=\"bold\")\n    plt.tight_layout()\n    plt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6229864",
   "metadata": {},
   "outputs": [],
   "source": "# Cell-14 : MNIST digit class distribution (dataset analysis)\n\nlabels_sample = [mnist_train[i][1] for i in range(0, len(mnist_train), 60)]\ncounts        = Counter(labels_sample)\nsorted_counts = sorted(counts.items())\n\nplt.figure(figsize=(8, 4))\nplt.bar([str(k) for k, _ in sorted_counts], [v for _, v in sorted_counts],\n        color=\"steelblue\", edgecolor=\"white\")\nplt.title(\"MNIST Digit Class Distribution (sampled)\", fontweight=\"bold\")\nplt.xlabel(\"Digit\")\nplt.ylabel(\"Count (sampled 1/60)\")\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "02471b34",
   "metadata": {},
   "source": [
    "## Part 3 — Model Comparison: DCGAN vs LSTM-MDN\n",
    "\n",
    "This section compares generated outputs and evaluation metrics for:\n",
    "- **DCGAN** image generation\n",
    "- **LSTM+MDN** stroke-sequence generation (rendered to image)\n",
    "\n",
    "> Run the training scripts (`src/train_dcgan.py`, `src/train_rnn.py`) first to populate the `reports/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1ed336",
   "metadata": {},
   "outputs": [],
   "source": "# Paths for pre-generated report artefacts\nREPORTS = Path('reports')\n\ndef show_if_exists(path, title=''):\n    path = Path(path)\n    if not path.exists():\n        print(f'Missing: {path}')\n        return\n    img = Image.open(path)\n    plt.figure(figsize=(6, 6))\n    plt.imshow(img, cmap='gray')\n    plt.axis('off')\n    plt.title(title or path.name)\n    plt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "b0332805",
   "metadata": {},
   "source": [
    "### Real and Generated Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98ce57c",
   "metadata": {},
   "outputs": [],
   "source": "show_if_exists(REPORTS / 'samples_dcgan.png', 'DCGAN Samples')\nshow_if_exists(REPORTS / 'samples_rnn.png', 'RNN Rendered Samples')"
  },
  {
   "cell_type": "markdown",
   "id": "2584fc57",
   "metadata": {},
   "source": [
    "### GAN Latent Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa7669e",
   "metadata": {},
   "outputs": [],
   "source": "show_if_exists(REPORTS / 'samples_dcgan_interp.png', 'DCGAN Interpolation')"
  },
  {
   "cell_type": "markdown",
   "id": "b85b34a1",
   "metadata": {},
   "source": [
    "### Stroke Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931b259a",
   "metadata": {},
   "outputs": [],
   "source": "show_if_exists(REPORTS / 'samples_rnn_strokes.png', 'RNN Raw Stroke Sequences')"
  },
  {
   "cell_type": "markdown",
   "id": "1dc39bae",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296fbedd",
   "metadata": {},
   "outputs": [],
   "source": "metrics_path = REPORTS / 'metrics.json'\nif metrics_path.exists():\n    with metrics_path.open('r', encoding='utf-8') as f:\n        metrics = json.load(f)\n    display(pd.DataFrame([metrics]).T.rename(columns={0: 'value'}))\nelse:\n    print(f'Missing: {metrics_path}')"
  },
  {
   "cell_type": "markdown",
   "id": "943b2291",
   "metadata": {},
   "source": [
    "### Short Conclusion\n",
    "\n",
    "Use this space to summarize which model looked sharper, which one produced more structured trajectories, and how classifier confidence/diversity compared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e00d2e",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Component | What we did |\n",
    "|---|---|\n",
    "| **Dataset** | MNIST Digits — 70,000 handwritten digit images (auto-downloaded into `data/`) |\n",
    "| **Sequence Modeling** | LSTM trained on synthetic pen-stroke (x,y) sequences; generates new strokes autoregressively |\n",
    "| **GAN Synthesis** | Generator + Discriminator trained adversarially on stroke segments; generates diverse new strokes from noise |\n",
    "| **DCGAN vs LSTM-MDN** | Pre-trained model outputs compared via sample images, latent interpolation, stroke plots, and quantitative metrics |\n",
    "| **Diagrams** | Dataset samples, class distribution, stroke visualisation, LSTM loss, Real vs LSTM, GAN loss, Real vs GAN |\n",
    "\n",
    "### Key Takeaways\n",
    "- **LSTM** captures temporal dynamics but suffers from error accumulation over long sequences\n",
    "- **GAN** generates diverse outputs but requires careful training to avoid mode collapse\n",
    "- Both approaches are complementary: LSTM for sequential fidelity, GAN for style diversity\n",
    "- **DCGAN** on image pixels and **LSTM-MDN** on stroke sequences represent two fundamentally different problem formulations — comparing them requires both visual and statistical evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
